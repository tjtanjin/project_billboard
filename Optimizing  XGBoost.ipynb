{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mass imports\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from xgboost.sklearn import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>hitmiss_spotify</th>\n",
       "      <th>duration</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>tempo_confidence</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>time_signature_confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>valence</th>\n",
       "      <th>chart_scraped</th>\n",
       "      <th>peak_position</th>\n",
       "      <th>weeks_billboard</th>\n",
       "      <th>hitmiss_billboard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2bezJO9Nc1yUCKTTuU1Y93</td>\n",
       "      <td>0</td>\n",
       "      <td>31/1/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>140.30766</td>\n",
       "      <td>-20.350</td>\n",
       "      <td>126.790</td>\n",
       "      <td>0.752</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2cMAHLrkaspfMWD8QRlODb</td>\n",
       "      <td>0</td>\n",
       "      <td>30/6/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>311.12154</td>\n",
       "      <td>-13.881</td>\n",
       "      <td>103.119</td>\n",
       "      <td>0.624</td>\n",
       "      <td>4</td>\n",
       "      <td>0.620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37ENbdGJLFfkwzlpQhZtyf</td>\n",
       "      <td>0</td>\n",
       "      <td>13/6/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>155.23084</td>\n",
       "      <td>-9.387</td>\n",
       "      <td>88.046</td>\n",
       "      <td>0.133</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3ctaMit7CuiHIPVYrRvm15</td>\n",
       "      <td>41</td>\n",
       "      <td>21/4/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>325.58195</td>\n",
       "      <td>-4.549</td>\n",
       "      <td>129.969</td>\n",
       "      <td>0.798</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5HQp90TwnVEJ2rsABskmxI</td>\n",
       "      <td>1</td>\n",
       "      <td>20/12/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>267.44866</td>\n",
       "      <td>-7.651</td>\n",
       "      <td>93.992</td>\n",
       "      <td>0.426</td>\n",
       "      <td>4</td>\n",
       "      <td>0.992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  popularity release_date  hitmiss_spotify  \\\n",
       "0  2bezJO9Nc1yUCKTTuU1Y93           0    31/1/2014                0   \n",
       "1  2cMAHLrkaspfMWD8QRlODb           0    30/6/2014                0   \n",
       "2  37ENbdGJLFfkwzlpQhZtyf           0    13/6/2014                0   \n",
       "3  3ctaMit7CuiHIPVYrRvm15          41    21/4/2014                0   \n",
       "4  5HQp90TwnVEJ2rsABskmxI           1   20/12/2014                0   \n",
       "\n",
       "    duration  loudness    tempo  tempo_confidence  time_signature  \\\n",
       "0  140.30766   -20.350  126.790             0.752               4   \n",
       "1  311.12154   -13.881  103.119             0.624               4   \n",
       "2  155.23084    -9.387   88.046             0.133               4   \n",
       "3  325.58195    -4.549  129.969             0.798               4   \n",
       "4  267.44866    -7.651   93.992             0.426               4   \n",
       "\n",
       "   time_signature_confidence        ...          danceability  energy  \\\n",
       "0                      1.000        ...                 0.519   0.184   \n",
       "1                      0.620        ...                 0.420   0.594   \n",
       "2                      1.000        ...                 0.761   0.723   \n",
       "3                      1.000        ...                 0.619   0.880   \n",
       "4                      0.992        ...                 0.768   0.567   \n",
       "\n",
       "   instrumentalness  liveness  speechiness  valence  chart_scraped  \\\n",
       "0          0.129000    0.1140       0.0359    0.444              0   \n",
       "1          0.000003    0.1260       0.0537    0.824              0   \n",
       "2          0.000072    0.1110       0.0472    0.810              0   \n",
       "3          0.001040    0.1660       0.0535    0.392              0   \n",
       "4          0.001160    0.0831       0.0552    0.348              0   \n",
       "\n",
       "   peak_position  weeks_billboard  hitmiss_billboard  \n",
       "0              0                0                  0  \n",
       "1              0                0                  0  \n",
       "2              0                0                  0  \n",
       "3              0                0                  0  \n",
       "4              0                0                  0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_combine = pd.read_csv(\"song_features/spotifybillboard_hitmiss_2014to18.csv\")\n",
    "songs_combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model training\n",
    "def model_score(x):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    xgb1 = XGBClassifier(\n",
    "        learning_rate =0.0775,\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        min_child_weight=0.1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "    x_train = x_train.values\n",
    "    x_test = x_test.values\n",
    "    xgb1.fit(x_train,y_train.values.ravel())\n",
    "    scores = cross_val_score(xgb1, x_train, y_train.values.ravel(), cv=10, scoring = \"roc_auc\")\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define y = hit/miss labels with cut-off\n",
    "y = songs_combine[['hitmiss_billboard']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['acousticness',\n",
       " 'danceability',\n",
       " 'duration',\n",
       " 'energy',\n",
       " 'instrumentalness',\n",
       " 'key',\n",
       " 'key_confidence',\n",
       " 'liveness',\n",
       " 'loudness',\n",
       " 'mode',\n",
       " 'mode_confidence',\n",
       " 'popularity',\n",
       " 'speechiness',\n",
       " 'tempo',\n",
       " 'tempo_confidence',\n",
       " 'time_signature',\n",
       " 'time_signature_confidence',\n",
       " 'valence']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_all=['duration','loudness', 'tempo','tempo_confidence','time_signature_confidence',\n",
    "                   'time_signature','key_confidence','mode_confidence',\n",
    "                   'key', 'mode', 'acousticness', 'danceability', 'energy',\n",
    "                   'instrumentalness', 'liveness', 'speechiness', 'valence','popularity']\n",
    "features_all.sort()\n",
    "print(len(features_all))\n",
    "features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_combination=[]\n",
    "models_score_combination=[]\n",
    "from itertools import combinations\n",
    "for i in range(16,19):\n",
    "    comb = combinations(features_all,i)\n",
    "    for i in list(comb):\n",
    "        features_combination.append(i)\n",
    "        list_i=list(i)    \n",
    "        models_score_combination.append(model_score(songs_combine[list_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n",
      "172\n"
     ]
    }
   ],
   "source": [
    "print(len(features_combination))\n",
    "print(len(models_score_combination))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8109921904559627"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(models_score_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acousticness',\n",
       " 'danceability',\n",
       " 'duration',\n",
       " 'energy',\n",
       " 'instrumentalness',\n",
       " 'key',\n",
       " 'liveness',\n",
       " 'loudness',\n",
       " 'mode',\n",
       " 'mode_confidence',\n",
       " 'popularity',\n",
       " 'speechiness',\n",
       " 'tempo',\n",
       " 'time_signature',\n",
       " 'time_signature_confidence',\n",
       " 'valence']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features=list(features_combination[models_score_combination.index(max(models_score_combination))])\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=songs_combine[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of scores generated: 3\n",
      "Scores generated: [0.8098468046930438, 0.8110419943698313, 0.8090547727692599]\n",
      "No. of learning rate tested: 3\n",
      "Best score achieved: 0.8110419943698313\n",
      "Best learning rate: 0.0774\n"
     ]
    }
   ],
   "source": [
    "#optimizing learning rate\n",
    "learning_rate=[0.0773,0.0774,0.0775]\n",
    "learning_rate_used=[]\n",
    "scores_generated=[]\n",
    "for i in learning_rate:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    xgb1 = XGBClassifier(\n",
    "        learning_rate =i,\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "    x_train = x_train.values\n",
    "    x_test = x_test.values\n",
    "    xgb1.fit(x_train,y_train.values.ravel())\n",
    "    scores = cross_val_score(xgb1, x_train, y_train.values.ravel(), cv=10, scoring = \"roc_auc\")\n",
    "    scores_generated.append(scores.mean())\n",
    "    learning_rate_used.append(i)\n",
    "print('No. of scores generated:', len(scores_generated))\n",
    "print('Scores generated:', scores_generated)\n",
    "print('No. of learning rate tested:', len(learning_rate_used))\n",
    "print('Best score achieved:',max(scores_generated))\n",
    "best_learning_rate_used=learning_rate_used[scores_generated.index(max(scores_generated))]\n",
    "print('Best learning rate:', best_learning_rate_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of scores generated: 3\n",
      "Scores generated: [0.8109429441654535, 0.8112509487133691, 0.8110259575273184]\n",
      "No. of n estimator tested: 3\n",
      "Best score achieved: 0.8112509487133691\n",
      "Best n estimator: 98\n"
     ]
    }
   ],
   "source": [
    "#optimizing n estimators\n",
    "n_estimators=[97,98,99]\n",
    "n_estimators_used=[]\n",
    "scores_generated=[]\n",
    "for i in n_estimators:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    xgb1 = XGBClassifier(\n",
    "        learning_rate =0.0774,\n",
    "        n_estimators=i,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "    x_train = x_train.values\n",
    "    x_test = x_test.values\n",
    "    xgb1.fit(x_train,y_train.values.ravel())\n",
    "    scores = cross_val_score(xgb1, x_train, y_train.values.ravel(), cv=10, scoring = \"roc_auc\")\n",
    "    scores_generated.append(scores.mean())\n",
    "    n_estimators_used.append(i)\n",
    "print('No. of scores generated:', len(scores_generated))\n",
    "print('Scores generated:', scores_generated)\n",
    "print('No. of n estimator tested:', len(n_estimators_used))\n",
    "print('Best score achieved:',max(scores_generated))\n",
    "best_n_estimators_used=n_estimators_used[scores_generated.index(max(scores_generated))]\n",
    "print('Best n estimator:', best_n_estimators_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of scores generated: 3\n",
      "Scores generated: [0.8087027920117024, 0.8112509487133691, 0.8110419665682163]\n",
      "No. of max depth tested: 3\n",
      "Best score achieved: 0.8112509487133691\n",
      "Best max depth: 5\n"
     ]
    }
   ],
   "source": [
    "#optimizing max depth\n",
    "max_depth=[4,5,6]\n",
    "max_depth_used=[]\n",
    "scores_generated=[]\n",
    "for i in max_depth:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    xgb1 = XGBClassifier(\n",
    "        learning_rate =0.0774,\n",
    "        n_estimators=98,\n",
    "        max_depth=i,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "    x_train = x_train.values\n",
    "    x_test = x_test.values\n",
    "    xgb1.fit(x_train,y_train.values.ravel())\n",
    "    scores = cross_val_score(xgb1, x_train, y_train.values.ravel(), cv=10, scoring = \"roc_auc\")\n",
    "    scores_generated.append(scores.mean())\n",
    "    max_depth_used.append(i)\n",
    "print('No. of scores generated:', len(scores_generated))\n",
    "print('Scores generated:', scores_generated)\n",
    "print('No. of max depth tested:', len(max_depth_used))\n",
    "print('Best score achieved:',max(scores_generated))\n",
    "best_max_depth_used=max_depth_used[scores_generated.index(max(scores_generated))]\n",
    "print('Best max depth:', best_max_depth_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of scores generated: 3\n",
      "Scores generated: [0.8127344094018818, 0.8127477339121214, 0.8124398183796183]\n",
      "No. of min child weight tested: 3\n",
      "Best score achieved: 0.8127477339121214\n",
      "Best min child weight: 0.05\n"
     ]
    }
   ],
   "source": [
    "#optimizing min child weight\n",
    "min_child_weight=[0.04,0.05,0.06]\n",
    "min_child_weight_used=[]\n",
    "scores_generated=[]\n",
    "for i in min_child_weight:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    xgb1 = XGBClassifier(\n",
    "        learning_rate =0.0774,\n",
    "        n_estimators=98,\n",
    "        max_depth=5,\n",
    "        min_child_weight=i,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "    x_train = x_train.values\n",
    "    x_test = x_test.values\n",
    "    xgb1.fit(x_train,y_train.values.ravel())\n",
    "    scores = cross_val_score(xgb1, x_train, y_train.values.ravel(), cv=10, scoring = \"roc_auc\")\n",
    "    scores_generated.append(scores.mean())\n",
    "    min_child_weight_used.append(i)\n",
    "print('No. of scores generated:', len(scores_generated))\n",
    "print('Scores generated:', scores_generated)\n",
    "print('No. of min child weight tested:', len(min_child_weight_used))\n",
    "print('Best score achieved:',max(scores_generated))\n",
    "best_min_child_weight_used=min_child_weight_used[scores_generated.index(max(scores_generated))]\n",
    "print('Best min child weight:', best_min_child_weight_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of scores generated: 6\n",
      "Scores generated: [0.8127477339121214, 0.8122417349700433, 0.8115541624233196, 0.8098882820231749, 0.8092947500307541, 0.8110663445651927]\n",
      "No. of gamma tested: 6\n",
      "Best score achieved: 0.8127477339121214\n",
      "Best gamma: 0\n"
     ]
    }
   ],
   "source": [
    "#optimizing gamma\n",
    "gamma=[0, 0.05,0.1,0.5,1,2]\n",
    "gamma_used=[]\n",
    "scores_generated=[]\n",
    "for i in gamma:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    xgb1 = XGBClassifier(\n",
    "        learning_rate =0.0774,\n",
    "        n_estimators=98,\n",
    "        max_depth=5,\n",
    "        min_child_weight=0.05,\n",
    "        gamma=i,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "    x_train = x_train.values\n",
    "    x_test = x_test.values\n",
    "    xgb1.fit(x_train,y_train.values.ravel())\n",
    "    scores = cross_val_score(xgb1, x_train, y_train.values.ravel(), cv=10, scoring = \"roc_auc\")\n",
    "    scores_generated.append(scores.mean())\n",
    "    gamma_used.append(i)\n",
    "print('No. of scores generated:', len(scores_generated))\n",
    "print('Scores generated:', scores_generated)\n",
    "print('No. of gamma tested:', len(gamma_used))\n",
    "print('Best score achieved:',max(scores_generated))\n",
    "best_gamma_used=gamma_used[scores_generated.index(max(scores_generated))]\n",
    "print('Best gamma:', best_gamma_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of scores generated: 3\n",
      "Scores generated: [0.8090346840925582, 0.8127477339121214, 0.8074010222473014]\n",
      "No. of subsample tested: 3\n",
      "Best score achieved: 0.8127477339121214\n",
      "Best subsample: 0.8\n"
     ]
    }
   ],
   "source": [
    "#optimizing subsample\n",
    "subsample=[0.79,0.8,0.81]\n",
    "subsample_used=[]\n",
    "scores_generated=[]\n",
    "for i in subsample:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    xgb1 = XGBClassifier(\n",
    "        learning_rate =0.0774,\n",
    "        n_estimators=98,\n",
    "        max_depth=5,\n",
    "        min_child_weight=0.05,\n",
    "        gamma=0,\n",
    "        subsample=i,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "    x_train = x_train.values\n",
    "    x_test = x_test.values\n",
    "    xgb1.fit(x_train,y_train.values.ravel())\n",
    "    scores = cross_val_score(xgb1, x_train, y_train.values.ravel(), cv=10, scoring = \"roc_auc\")\n",
    "    scores_generated.append(scores.mean())\n",
    "    subsample_used.append(i)\n",
    "print('No. of scores generated:', len(scores_generated))\n",
    "print('Scores generated:', scores_generated)\n",
    "print('No. of subsample tested:', len(subsample_used))\n",
    "print('Best score achieved:',max(scores_generated))\n",
    "best_subsample_used=subsample_used[scores_generated.index(max(scores_generated))]\n",
    "print('Best subsample:', best_subsample_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of scores generated: 3\n",
      "Scores generated: [0.8068894262204187, 0.8127477339121214, 0.8127477339121214]\n",
      "No. of colsample_bytree tested: 3\n",
      "Best score achieved: 0.8127477339121214\n",
      "Best colsample_bytree: 0.75\n"
     ]
    }
   ],
   "source": [
    "#optimizing colsample_bytree\n",
    "colsample_bytree=[0.74,0.75,0.76]\n",
    "colsample_bytree_used=[]\n",
    "scores_generated=[]\n",
    "for i in colsample_bytree:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    xgb1 = XGBClassifier(\n",
    "        learning_rate =0.0774,\n",
    "        n_estimators=98,\n",
    "        max_depth=5,\n",
    "        min_child_weight=0.05,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=i,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "    x_train = x_train.values\n",
    "    x_test = x_test.values\n",
    "    xgb1.fit(x_train,y_train.values.ravel())\n",
    "    scores = cross_val_score(xgb1, x_train, y_train.values.ravel(), cv=10, scoring = \"roc_auc\")\n",
    "    scores_generated.append(scores.mean())\n",
    "    colsample_bytree_used.append(i)\n",
    "print('No. of scores generated:', len(scores_generated))\n",
    "print('Scores generated:', scores_generated)\n",
    "print('No. of colsample_bytree tested:', len(colsample_bytree_used))\n",
    "print('Best score achieved:',max(scores_generated))\n",
    "best_colsample_bytree_used=colsample_bytree_used[scores_generated.index(max(scores_generated))]\n",
    "print('Best colsample_bytree:', best_colsample_bytree_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of scores generated: 3\n",
      "Scores generated: [0.8127477339121214, 0.8127477339121214, 0.8127477339121214]\n",
      "No. of nthread tested: 3\n",
      "Best score achieved: 0.8127477339121214\n",
      "Best nthread: 0\n"
     ]
    }
   ],
   "source": [
    "#optimizing nthread\n",
    "nthread=[0,4,10]\n",
    "nthread_used=[]\n",
    "scores_generated=[]\n",
    "for i in nthread:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    xgb1 = XGBClassifier(\n",
    "        learning_rate =0.0774,\n",
    "        n_estimators=98,\n",
    "        max_depth=5,\n",
    "        min_child_weight=0.05,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.75,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=i,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "    x_train = x_train.values\n",
    "    x_test = x_test.values\n",
    "    xgb1.fit(x_train,y_train.values.ravel())\n",
    "    scores = cross_val_score(xgb1, x_train, y_train.values.ravel(), cv=10, scoring = \"roc_auc\")\n",
    "    scores_generated.append(scores.mean())\n",
    "    nthread_used.append(i)\n",
    "print('No. of scores generated:', len(scores_generated))\n",
    "print('Scores generated:', scores_generated)\n",
    "print('No. of nthread tested:', len(nthread_used))\n",
    "print('Best score achieved:',max(scores_generated))\n",
    "best_nthread_used=nthread_used[scores_generated.index(max(scores_generated))]\n",
    "print('Best nthread:', best_nthread_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of scores generated: 3\n",
      "Scores generated: [0.808840399622962, 0.8127477339121214, 0.8095936849716454]\n",
      "No. of scale_pos_weight tested: 3\n",
      "Best score achieved: 0.8127477339121214\n",
      "Best scale_pos_weight: 1\n"
     ]
    }
   ],
   "source": [
    "#optimizing scale_pos_weight\n",
    "scale_pos_weight=[0.9,1,1.1]\n",
    "scale_pos_weight_used=[]\n",
    "scores_generated=[]\n",
    "for i in scale_pos_weight:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    xgb1 = XGBClassifier(\n",
    "        learning_rate =0.0774,\n",
    "        n_estimators=98,\n",
    "        max_depth=5,\n",
    "        min_child_weight=0.05,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.75,\n",
    "        objective= 'binary:logistic',\n",
    "        scale_pos_weight=i,\n",
    "        seed=27)\n",
    "    x_train = x_train.values\n",
    "    x_test = x_test.values\n",
    "    xgb1.fit(x_train,y_train.values.ravel())\n",
    "    scores = cross_val_score(xgb1, x_train, y_train.values.ravel(), cv=10, scoring = \"roc_auc\")\n",
    "    scores_generated.append(scores.mean())\n",
    "    scale_pos_weight_used.append(i)\n",
    "print('No. of scores generated:', len(scores_generated))\n",
    "print('Scores generated:', scores_generated)\n",
    "print('No. of scale_pos_weight tested:', len(scale_pos_weight_used))\n",
    "print('Best score achieved:',max(scores_generated))\n",
    "best_scale_pos_weight_used=scale_pos_weight_used[scores_generated.index(max(scores_generated))]\n",
    "print('Best scale_pos_weight:', best_scale_pos_weight_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8127477339121214"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2,random_state=1)\n",
    "    \n",
    "xgb1 = XGBClassifier(\n",
    "        learning_rate =0.0774,\n",
    "        n_estimators=98,\n",
    "        max_depth=5,\n",
    "        min_child_weight=0.05,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.75,\n",
    "        objective= 'binary:logistic',\n",
    "        scale_pos_weight=1,\n",
    "        seed=27\n",
    "        )\n",
    "x_train = x_train.values\n",
    "x_test = x_test.values\n",
    "xgb1.fit(x_train,y_train.values.ravel())\n",
    "scores = cross_val_score(xgb1, x_train, y_train.values.ravel(), cv=10, scoring = \"roc_auc\")\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
